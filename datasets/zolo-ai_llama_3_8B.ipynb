{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-JXaxDMKNow"
   },
   "outputs": [],
   "source": [
    "# !pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1713642179220,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "aIBipO8zKO8n",
    "outputId": "ce1ca08d-5d59-4a95-85c0-028fdf0141bc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1713642181566,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "qQ_if-2qKuOD",
    "outputId": "53f43a18-e2c6-4a22-ef96-d6dd4889be10"
   },
   "outputs": [],
   "source": [
    "#######################------Enter Your Project Directory Path in Google Drive-----####################################################\n",
    "project_directory_path = \"/content/drive/MyDrive/mistral_qa/\"\n",
    "%cd $project_directory_path\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5945,
     "status": "ok",
     "timestamp": 1713641916761,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "lvK-uypZJm4k"
   },
   "outputs": [],
   "source": [
    "# Run this cell to install required dependencies\n",
    "!pip install -q accelerate peft bitsandbytes transformers trl nanoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 20440,
     "status": "ok",
     "timestamp": 1713642205100,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "01AQgGOXJ_Un"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from nanoid import generate\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                   AutoTokenizer,\n",
    "                   BitsAndBytesConfig,\n",
    "                   HfArgumentParser,\n",
    "                   TrainingArguments,\n",
    "                   TextDataset,\n",
    "                   DataCollatorForLanguageModeling,\n",
    "                   pipeline,\n",
    "\n",
    "\n",
    "                   logging)\n",
    "from accelerate import Accelerator\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# ***********************************************************************************************************************************************\n",
    "# Log in to your HuggingFace account\n",
    "# Agree to condition from this page \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# Agree to condition from this page https://huggingface.co/google/gemma-7b\n",
    "# Agree to condition from this page https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
    "# ***********************************************************************************************************************************************\n",
    "# Enter your access token from \"https://huggingface.co/settings/tokens\"\n",
    "# <<<<<<<<<<<<Your Access Token Goes Here inside \" \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "access_token = \"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\"\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /teamspace/studios/this_studio/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQBu1xZmC6_h"
   },
   "source": [
    "# LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713643825264,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "QWTpQl8CC6ed"
   },
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "# new_model = \"Mistral-7B-Instruct-v0.2\"\n",
    "new_model = \"Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# QLoRA parameters\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 32\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "# bitsandbytes parameters\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# TrainingArguments parameters\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# SFT parameters\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9536c46d76a241e1a49b8e6e0f4946ff",
      "5be01ac663f9488cbc1bf04a6a85b1c5",
      "a998386fd88d4671a6384e889b12bea7",
      "e74de869afe74debaa7e78a5e2721e3c",
      "99b8ed123a5746b99a3bbdd299532b53",
      "ecf6b354f80b49779849675da008ac4b",
      "60155193c0d74a86914b3dae2eefb3e0",
      "f8354eb11ecd4b65859a399838de8417",
      "a383ae1fd7274b4eaa6a9129ee30b61a",
      "3d99d30ced264949b6375a8e0499b004",
      "4f8ce5bfee454166ae87063b5ca3b247"
     ]
    },
    "executionInfo": {
     "elapsed": 82377,
     "status": "ok",
     "timestamp": 1713643911360,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "rpXqa3iXDKIm",
    "outputId": "cac8aa60-697c-4576-a1d5-5fc75d0c889f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6557d34167174ef48df27013f107898f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map= device_map,\n",
    "    low_cpu_mem_usage=True,\n",
    "    token = access_token\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, token = access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules = [\n",
    "    \"lm_head\",\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"up_proj\",\n",
    "    \"down_proj\",\n",
    "    \"o_proj\",\n",
    "    \"gate_proj\"\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################################################################################################################\n",
      "-------------------------------------------------- Architechture of the LLM model is given below --------------------------------------------------\n",
      "###################################################################################################################################################\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "###################################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#\"*147)\n",
    "print(\"-\"*50 , \"Architechture of the LLM model is given below\", \"-\"*50)\n",
    "print(\"#\"*147)\n",
    "print(model)\n",
    "print(\"#\"*147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3cEbg0IKSsl-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints for train 3420\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "# <<<<<<<<<<<<<You can upload the processed dataset into your HuggingFace and replace the dataset_name path with the corresponding one>>>>>>>>>>>>>>>>>>\n",
    "dataset_name = \"shetumohanto/zoloai\"\n",
    "dataset = load_dataset(dataset_name, split='train')\n",
    "dataset = dataset.shuffle(seed = 314)\n",
    "print(f\"Total datapoints for train {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<s> [INST] <<SYS>> Generate ZOLO block code required for the user input. Strictly follow the output format. Start output with ++ and end with ++ <<\\\\SYS>> User input: Develop an image section displaying a serene garden setting. [/INST] ++Output = {\"Block_Name\": \"Advanced_Image\", \"Image_Source\":\"UPLOAD\", \"Layout\":{\"HEADING\":\"Sunset Spectacle: Nature\\'s Colorful Canvas\", \"DESCRIPTION\":\"Feel the cool mist on your face as water crashes down.\"}}++ </s> \\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset, model, type=\"train\", max_seq_length=256):\n",
    "    model_max_seq_length = model.config.max_position_embeddings\n",
    "    print(f\"Model can handle maximum {model_max_seq_length} tokens\")\n",
    "    \n",
    "    length = [len(tokenizer.encode(data[\"text\"])) for data in dataset]\n",
    "    print(f\"Max sequence length in the {type} dataset is {max(length)}\")\n",
    "\n",
    "    test_length = length.copy()\n",
    "    # remove datapoints greater that sequence length of max_seq_length due to GPU fit.\n",
    "    test_length = [element for element in length if element < max_seq_length]\n",
    "    print(f\"Total datapoints in {type} dataset after removing sequence length greater than {max_seq_length} is {len(test_length)}\")\n",
    "\n",
    "    include_idx = [index for index, element in enumerate(length) if element < max_seq_length]\n",
    "\n",
    "    dataset_dict = dataset[include_idx]\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    length = [len(tokenizer.encode(data[\"text\"])) for data in dataset]\n",
    "    print(\"Max sequence length after filtering is {}\".format(max(length)))\n",
    "    \n",
    "    max_seq_length = 2**round(math.log2(max(length)))\n",
    "    print(\"Max sequence length set to {}\".format(max_seq_length))\n",
    "\n",
    "    return dataset, max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model can handle maximum 8192 tokens\n",
      "Max sequence length in the train dataset is 231\n",
      "Total datapoints in train dataset after removing sequence length greater than 256 is 3420\n",
      "Max sequence length after filtering is 231\n",
      "Max sequence length set to 256\n"
     ]
    }
   ],
   "source": [
    "dataset, max_seq_length = filter_dataset(dataset, model, type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc5AowmjKNo8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# For Training Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "030603b157f5432baefe665dad4d6448"
     ]
    },
    "id": "Vze-kzstIFLJ",
    "outputId": "7c68566b-2bf8-4417-cf1b-db58932f1773"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118ba4a75b4f44eb94a0f1ac4da6ef15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 59:45, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs\n",
    "num_train_epochs = 4\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 1\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 3\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "#     lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"none\",\n",
    "    logging_steps = 100\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3oPrTv-MRTC"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6205,
     "status": "ok",
     "timestamp": 1713644007986,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "bP6CZOHgOVQ2"
   },
   "outputs": [],
   "source": [
    "#######--------Run this cell only once----------###############\n",
    "# peft_model_id = \"Mistral-7B-Instruct-v0.2\"\n",
    "peft_model_id = \"Meta-Llama-3-8B-Instruct\"\n",
    "model.load_adapter(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1713644024252,
     "user": {
      "displayName": "Shetu Mohanto",
      "userId": "13289953683899358895"
     },
     "user_tz": -360
    },
    "id": "Hi7Lb0JcKNo9"
   },
   "outputs": [],
   "source": [
    "def generate_text(prompt, model, tokenizer):\n",
    "    # if model._get_name() == \"GemmaForCausalLM\":\n",
    "    #     prompt = f\"\"\"<start_of_turn>user {prompt} <end_of_turn> <start_of_turn>model \"\"\"\n",
    "    # else:\n",
    "    prompt = f\"\"\"<s> [INST] <<SYS>> Generate ZOLO block format required for the user input. Start output with ++ and end with ++. \n",
    "    Please provide text inside Output items aligned with the user input. Do not output any code. Please provide only one output.\n",
    "    <<\\\\SYS>> User input: {prompt} [/INST]\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_out = model.generate(**inputs, max_new_tokens=max_seq_length, pad_token_id=2)\n",
    "        generated_text = tokenizer.decode(model_out[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text, model_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nanoid import generate\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "from zolo_blocks.accordion import Accordion\n",
    "from zolo_blocks.advance_button import Advance_Button\n",
    "from zolo_blocks.advance_heading import Advance_Heading\n",
    "from zolo_blocks.advance_image import Advance_Image\n",
    "from zolo_blocks.container import Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(user_query, model, tokenizer):\n",
    "    block_list = [Accordion, Advance_Button, Advance_Heading, Advance_Image, Container]\n",
    "    block_name_list = [\"Accordion\", \"Advanced_Button\", \"Advanced_Heading\", \"Advanced_Image\", \"Container\"]\n",
    "    \n",
    "    model_out, _ = generate_text(user_query, model, tokenizer)\n",
    "    # print(model_out)\n",
    "    # model_out = model_out.split(\"++\")[3].replace(\"Output\", \"\").replace(\"=\", \"\").strip()\n",
    "    pattern = re.compile(re.escape(\"[/INST]\") + '(.*?)' + re.escape(\"</s>\"))\n",
    "    model_out = pattern.search(model_out).group(1).replace(\"Output\", \"\").replace(\"=\", \"\").replace(\"++\", \"\").strip()\n",
    "    model_out = ast.literal_eval(model_out)\n",
    "    block_name = model_out[\"Block_Name\"]\n",
    "    block_index = block_name_list.index(block_name)\n",
    "    code_generator = block_list[block_index]\n",
    "    code_out = code_generator(model_out)\n",
    "    code = code_out.get_code()\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################################################################################################################\n",
      "<!-- wp:zolo/container {\"variationStatus\":true,\"isBlockRootParent\":true,\"uniqueId\":\"container-3j3c6k1p\",\"parentClasses\":[\"zolo-block parent-container-3j3c6k1p\"],\"zoloStyles\":{\"desktop\":\".container-3j3c6k1p.block-editor-block-list__block.wp-block-zolo-container \\u003e .zolo-container-inner-blocks-wrap,.wp-block-zolo-container.zolo-root-container.alignfull.container-3j3c6k1p \\u003e .zolo-container-inner-blocks-wrap { max-width:1200px }.is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-6re27zfq-f1vj-ia2g-7mu3-tyh4u9jurred,.wp-block-zolo-container.zolo-root-container.frontend .container-3j3c6k1p { max-width:100%; width:100% }.container-3j3c6k1p.wp-block-zolo-container \\u003e .zolo-container-inner-blocks-wrap \\u003e .block-editor-inner-blocks \\u003e .block-editor-block-list__layout,.container-3j3c6k1p.wp-block-zolo-container.zolo-root-container.alignfull \\u003e .zolo-container-inner-blocks-wrap { gap:20px; flex-direction:row; flex-wrap:nowrap; justify-content:center; align-items:center }\",\"tab\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-6re27zfq-f1vj-ia2g-7mu3-tyh4u9jurred,.wp-block-zolo-container.zolo-root-container.frontend .container-3j3c6k1p { width:100% }\",\"mobile\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-6re27zfq-f1vj-ia2g-7mu3-tyh4u9jurred,.wp-block-zolo-container.zolo-root-container.frontend .container-3j3c6k1p { width:100% }\"}} --> <div class=\"wp-block-zolo-container container-3j3c6k1p alignfull zolo-root-container frontend zolo-block parent-container-3j3c6k1p\" > <div class=\"zolo-container-inner-blocks-wrap\"> <!-- wp:zolo/container {\"zolo_ContainerWidthRange\":33.33,\"zolo_TABContainerWidthRange\":100,\"zolo_TABContainerWidthUnit\":\"%\",\"FlexDirectionZRPAlign\":\"column\",\"uniqueId\":\"container-mgzx72e1\",\"parentClasses\":[\"zolo-block parent-container-mgzx72e1\"],\"zoloStyles\":{\"desktop\":\".container-mgzx72e1.block-editor-block-list__block.wp-block-zolo-container \\u003e .zolo-container-inner-blocks-wrap,.wp-block-zolo-container.zolo-root-container.alignfull.container-mgzx72e1 \\u003e .zolo-container-inner-blocks-wrap { max-width:1200px }.is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-24jqdql2-7l6h-9qb2-m2rp-c3lrlry57f6v,.wp-block-zolo-container.zolo-root-container.frontend .container-mgzx72e1 { max-width:33.33%; width:100% }.container-mgzx72e1.wp-block-zolo-container \\u003e .block-editor-inner-blocks \\u003e .block-editor-block-list__layout,.container-mgzx72e1.wp-block-zolo-container.frontend { gap:20px; flex-direction:column; flex-wrap:nowrap; justify-content:center; align-items:center }\",\"tab\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-24jqdql2-7l6h-9qb2-m2rp-c3lrlry57f6v,.wp-block-zolo-container.zolo-root-container.frontend .container-mgzx72e1 { max-width:100%; width:100% }\",\"mobile\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-24jqdql2-7l6h-9qb2-m2rp-c3lrlry57f6v,.wp-block-zolo-container.zolo-root-container.frontend .container-mgzx72e1 { width:100% }\"}} --> <div class=\"wp-block-zolo-container container-mgzx72e1 frontend zolo-block parent-container-mgzx72e1\" > <!-- wp:paragraph --> <p>Smartphones wield immense influence on social behavior and interpersonal relationships, altering how we engage and communicate.</p> <!-- /wp:paragraph --> </div> <!-- /wp:zolo/container --> <!-- wp:zolo/container {\"zolo_ContainerWidthRange\":33.33,\"zolo_TABContainerWidthRange\":100,\"zolo_TABContainerWidthUnit\":\"%\",\"FlexDirectionZRPAlign\":\"column\",\"uniqueId\":\"container-gjbgmpli\",\"parentClasses\":[\"zolo-block parent-container-gjbgmpli\"],\"zoloStyles\":{\"desktop\":\".container-gjbgmpli.block-editor-block-list__block.wp-block-zolo-container \\u003e .zolo-container-inner-blocks-wrap,.wp-block-zolo-container.zolo-root-container.alignfull.container-gjbgmpli \\u003e .zolo-container-inner-blocks-wrap { max-width:1200px }.is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-di1bxij9-it36-duh7-nl9k-q59ecdlt4qbc,.wp-block-zolo-container.zolo-root-container.frontend .container-gjbgmpli { max-width:33.33%; width:100% }.container-gjbgmpli.wp-block-zolo-container \\u003e .block-editor-inner-blocks \\u003e .block-editor-block-list__layout,.container-gjbgmpli.wp-block-zolo-container.frontend { gap:20px; flex-direction:column; flex-wrap:nowrap; justify-content:center; align-items:center }\",\"tab\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-di1bxij9-it36-duh7-nl9k-q59ecdlt4qbc,.wp-block-zolo-container.zolo-root-container.frontend .container-gjbgmpli { max-width:100%; width:100% }\",\"mobile\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-di1bxij9-it36-duh7-nl9k-q59ecdlt4qbc,.wp-block-zolo-container.zolo-root-container.frontend .container-gjbgmpli { width:100% }\"}} --> <div class=\"wp-block-zolo-container container-gjbgmpli frontend zolo-block parent-container-gjbgmpli\" > <!-- wp:paragraph --> <p>The implications of 5G deployment for various industries are summarized briefly, highlighting transformative potentials.</p> <!-- /wp:paragraph --> </div> <!-- /wp:zolo/container --> <!-- wp:zolo/container {\"zolo_ContainerWidthRange\":33.33,\"zolo_TABContainerWidthRange\":100,\"zolo_TABContainerWidthUnit\":\"%\",\"FlexDirectionZRPAlign\":\"column\",\"uniqueId\":\"container-pgfevgr3\",\"parentClasses\":[\"zolo-block parent-container-pgfevgr3\"],\"zoloStyles\":{\"desktop\":\".container-pgfevgr3.block-editor-block-list__block.wp-block-zolo-container \\u003e .zolo-container-inner-blocks-wrap,.wp-block-zolo-container.zolo-root-container.alignfull.container-pgfevgr3 \\u003e .zolo-container-inner-blocks-wrap { max-width:1200px }.is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-1yy63qls-jmsm-i1lo-nw28-586xsz9gbvek,.wp-block-zolo-container.zolo-root-container.frontend .container-pgfevgr3 { max-width:33.33%; width:100% }.container-pgfevgr3.wp-block-zolo-container \\u003e .block-editor-inner-blocks \\u003e .block-editor-block-list__layout,.container-pgfevgr3.wp-block-zolo-container.frontend { gap:20px; flex-direction:column; flex-wrap:nowrap; justify-content:center; align-items:center }\",\"tab\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-1yy63qls-jmsm-i1lo-nw28-586xsz9gbvek,.wp-block-zolo-container.zolo-root-container.frontend .container-pgfevgr3 { max-width:100%; width:100% }\",\"mobile\":\".is-root-container \\u003e .block-editor-block-list__block .block-editor-block-list__block#block-1yy63qls-jmsm-i1lo-nw28-586xsz9gbvek,.wp-block-zolo-container.zolo-root-container.frontend .container-pgfevgr3 { width:100% }\"}} --> <div class=\"wp-block-zolo-container container-pgfevgr3 frontend zolo-block parent-container-pgfevgr3\" > <!-- wp:paragraph --> <p>In modern life, mobile devices offer unparalleled convenience and utility, seamlessly integrating into daily routines.</p> <!-- /wp:paragraph --> </div> <!-- /wp:zolo/container --> </div> </div> <!-- /wp:zolo/container --> <!-- wp:paragraph --> <p></p> <!-- /wp:paragraph -->\n",
      "##########################################################################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Examine the environmental impact of mango, litchi, and banana cultivation.\"\n",
    "code = generate_code(user_query, model, tokenizer)\n",
    "print(\"#\"*170)\n",
    "print(code)\n",
    "print(\"#\"*170)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "W5tvYglTvHK7"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3d99d30ced264949b6375a8e0499b004": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f8ce5bfee454166ae87063b5ca3b247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5be01ac663f9488cbc1bf04a6a85b1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecf6b354f80b49779849675da008ac4b",
      "placeholder": "​",
      "style": "IPY_MODEL_60155193c0d74a86914b3dae2eefb3e0",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "60155193c0d74a86914b3dae2eefb3e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9536c46d76a241e1a49b8e6e0f4946ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5be01ac663f9488cbc1bf04a6a85b1c5",
       "IPY_MODEL_a998386fd88d4671a6384e889b12bea7",
       "IPY_MODEL_e74de869afe74debaa7e78a5e2721e3c"
      ],
      "layout": "IPY_MODEL_99b8ed123a5746b99a3bbdd299532b53"
     }
    },
    "99b8ed123a5746b99a3bbdd299532b53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a383ae1fd7274b4eaa6a9129ee30b61a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a998386fd88d4671a6384e889b12bea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8354eb11ecd4b65859a399838de8417",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a383ae1fd7274b4eaa6a9129ee30b61a",
      "value": 3
     }
    },
    "e74de869afe74debaa7e78a5e2721e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d99d30ced264949b6375a8e0499b004",
      "placeholder": "​",
      "style": "IPY_MODEL_4f8ce5bfee454166ae87063b5ca3b247",
      "value": " 3/3 [01:17&lt;00:00, 25.72s/it]"
     }
    },
    "ecf6b354f80b49779849675da008ac4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8354eb11ecd4b65859a399838de8417": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
